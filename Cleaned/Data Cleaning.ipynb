{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning \n",
    "\n",
    "\n",
    "**CS 109a: Airbnb**\n",
    "\n",
    "**Richa Chaturvedi, Mirai Shah, and Sam Plank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import re\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import datetime as dt\n",
    "import math\n",
    "from sklearn.linear_model import Lasso as Lasso_Reg\n",
    "import numpy as np \n",
    "import sklearn.preprocessing as Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler as Standardize\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.linear_model import Ridge as Ridge_Reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Calendar Dataset\n",
    "\n",
    "The calendar dataset gives the price of listings over the course of a year.  In order to clean this dataset, we first renamed the columns with more appropriate labels.  We then stripped the dates and prices of their extraneous characters so they were easier to work with.  Finally, we converted the column types to apropriate dytpes and filtered out columns with no information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open calendar csv file\n",
    "calendar = pd.read_csv('calendar.csv', delimiter = '\\t') \n",
    "\n",
    "# rename columns \n",
    "calendar[\"listing\"], calendar['date'], calendar['available'], calendar['price'] = zip(*calendar['listing_id,\"date\",\"available\",\"price\"'].str.split(',').tolist())\n",
    "calendar = calendar.drop(['listing_id,\"date\",\"available\",\"price\"'], 1)\n",
    "\n",
    "# change column contents to be more workable format\n",
    "calendar['date'] = calendar['date'].map(lambda x: x.lstrip('\"').rstrip('\"'))\n",
    "calendar['price'] = calendar['price'].map(lambda x: x.lstrip('$').rstrip('.'))\n",
    "\n",
    "# change column dtypes \n",
    "calendar['price'] = pd.to_numeric(calendar['price'])\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "calendar['listing'] = pd.to_numeric(calendar['listing'])\n",
    "\n",
    "# filter out the columns with no prices \n",
    "calendar=calendar[calendar['available'] == 't']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Listings Dataset\n",
    "\n",
    "The listings dataset is our main dataset for this project.  It contains thousands of rows of listing information for Airbnbs in New York City.  We attempted to clean the data many different ways before settling on our final dataset.  One notable technique we tried was KNN.  Ultimately, this was unsuccessful because most rows had some NaN values and it was therefore difficult to find similar listings.  KNN ended up being too costly and ineffective.\n",
    "\n",
    "First, we dropped the columns with null values that added no values to the dataset.  We then dropped null values that could not be salvaged (things that could not be filled in based off of any known technique or our intuition such as ID or property type).  \n",
    "\n",
    "Next, we changed the format of two variables (price and extra people) to integers rather than objects so we could easily perform statistical procedures with the information provided.  The zipcodes were given in their extended form, so we decided to only use the first five numbers.  \n",
    "\n",
    "For missing weekly and monthly prices, we used scaled nightly price to fill in the missing data.  Finally, we replaced some (host since, etc.) with the columns from our sentiment analysis dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open dataset with information and pricing for each listing \n",
    "df = pd.read_csv('listings.csv',encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop columns with null values that don't add important information to dataset\n",
    "df = df.drop(['country', 'neighbourhood', 'square_feet', 'state'], 1)\n",
    "\n",
    "# drop null values that can't be salvaged \n",
    "df = df[(pd.notnull(df['id']))&(pd.notnull(df['host_id']))&(pd.notnull(df['zipcode']))&(pd.notnull(df['latitude']))]\n",
    "df = df[(pd.notnull(df['longitude']))&(pd.notnull(df['bathrooms']))&(pd.notnull(df['bedrooms']))&(pd.notnull(df['beds']))]\n",
    "df = df[(pd.notnull(df['property_type']))&(pd.notnull(df['price']))&((df.number_of_reviews!=0)&(pd.notnull(df.review_scores_rating)))]\n",
    "\n",
    "# reset index after dropping certain rows\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# change format of prices and extra_people to integer rather than object\n",
    "prices = []\n",
    "extra_people = []\n",
    "for i in range(len(df)):\n",
    "    price = int(float(str(df['price'][i]).replace('$', '').replace(',', '')))\n",
    "    extra_person = int(float(str(df['extra_people'][i]).replace('$', '').replace(',', '')))\n",
    "    prices.append(price)\n",
    "    extra_people.append(extra_person)\n",
    "\n",
    "df['price'] = prices\n",
    "df['extra_people'] = extra_people\n",
    "\n",
    "# only keep first five numbers of zipcode \n",
    "zipcodes = []\n",
    "for i in range(len(df)):\n",
    "    zipcode = df['zipcode'][i][:5]\n",
    "    zipcodes.append(zipcode)\n",
    "df['zipcode'] = zipcodes\n",
    "\n",
    "# fill the null values in weekly_prices and monthly_prices column\n",
    "# change the dtype from object to integer in these two columns\n",
    "wprices = []\n",
    "mprices = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if pd.isnull(df['weekly_price'][i]):\n",
    "        wprice = df['price'][i] * 7\n",
    "    elif pd.notnull(df['weekly_price'][i]):\n",
    "        wprice = int(float(str(df['weekly_price'][i]).replace('$', '').replace(',', '')))\n",
    "    wprices.append(wprice)\n",
    "    if pd.isnull(df['monthly_price'][i]):\n",
    "        mprice = df['price'][i] * 30\n",
    "    elif pd.notnull(df['monthly_price'][i]):\n",
    "        mprice = int(float(str(df['monthly_price'][i]).replace('$', '').replace(',', '')))\n",
    "    mprices.append(mprice)\n",
    "    \n",
    "df['weekly_price'] = wprices\n",
    "df['monthly_price'] = mprices\n",
    "\n",
    "df = df.dropna(axis=0)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop the original host_since, first_review, last_review\n",
    "df = df.drop(['host_since', 'first_review', 'last_review'], 1)\n",
    "\n",
    "# add in new csv with the sentiment columns and converted host_since, first_review, last_review columns\n",
    "sentiment = pd.read_csv('time_sentiment.csv')\n",
    "\n",
    "host_since = sentiment['host_since'] \n",
    "first_review = sentiment['first_review'] \n",
    "last_review = sentiment['last_review'] \n",
    "sentiments = sentiment['sentiment']\n",
    "\n",
    "frames = [host_since, first_review, last_review, sentiments]\n",
    "final_sentiment = pd.concat(frames, 1)\n",
    "final_sentiment = final_sentiment.dropna(axis=0, how='any')\n",
    "frames_new = [df, final_sentiment]\n",
    "\n",
    "df_final = pd.concat(frames_new, 1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
